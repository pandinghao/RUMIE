import json
import random
from collections import Counter
from typing import List, Dict, Any
import os
import cv2

def load_jsonl(path: str) -> List[Dict[str, Any]]:
    """è¯»å– jsonl æ–‡ä»¶ï¼Œä¸€è¡Œä¸€ä¸ª json å¯¹è±¡"""
    data = []
    with open(path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            data.append(json.loads(line))
    return data


def count_relation_types(data: List[Dict[str, Any]]) -> Counter:
    """
    ç»Ÿè®¡æ‰€æœ‰æ ·æœ¬ä¸­ relation.type çš„æ•°é‡ã€‚
    æ¯ä¸€æ¡å…³ç³»å•ç‹¬è®¡æ•°ï¼ŒåŒ…æ‹¬ type == "none" çš„è´Ÿä¾‹å…³ç³»ï¼ˆå¦‚æœæ•°æ®é‡Œæœ‰ï¼‰ã€‚
    """
    type_counter = Counter()
    for ex in data:
        for rel in ex.get("relation", []):
            rel_type = rel.get("type")
            if rel_type is not None:
                type_counter[rel_type] += 1
    return type_counter


def stratified_sample_keep_relation_ratio(
    data: List[Dict[str, Any]],
    sample_ratio: float = 0.2,
    seed: int = 42
) -> List[Dict[str, Any]]:
    """
    åœ¨å°½é‡ä¿æŒâ€œå…³ç³»ç±»åˆ«â€æ•´ä½“æ¯”ä¾‹ä¸å˜çš„å‰æä¸‹ï¼Œå¯¹ MNRE æ ·æœ¬è¿›è¡Œåˆ†å±‚é‡‡æ ·ã€‚
    ï¼ˆåŒ…æ‹¬ none ç±»åˆ«ï¼Œåªè¦å®ƒåœ¨ relation.type é‡Œå‡ºç°ï¼‰

    æ€è·¯ï¼ˆå…³ç³»çº§åˆ†å¸ƒçº¦æŸï¼Œæ ·æœ¬ä¸ºå•ä½ï¼‰ï¼š
      1. ç»Ÿè®¡æ‰€æœ‰æ ·æœ¬ä¸­çš„å…³ç³»ç±»å‹è®¡æ•° total_countsï¼ˆé€æ¡ relation è®¡æ•°ï¼‰ã€‚
      2. è®¡ç®—ç›®æ ‡é‡‡æ ·è®¡æ•° target_counts = total_counts * sample_ratioï¼Œä¸”æ¯ç±»è‡³å°‘ä¸º 1ã€‚
      3. æ‰“ä¹±æ ·æœ¬é¡ºåºï¼Œä¾æ¬¡éå†ï¼š
         - å¯¹æ¯ä¸ªæ ·æœ¬ï¼Œçœ‹å®ƒåŒ…å«çš„å…³ç³»ç±»å‹ï¼Œå¦‚æœå…¶ä¸­è‡³å°‘æœ‰ä¸€ä¸ªç±»å‹ current_counts[t] < target_counts[t]ï¼Œ
           å°±æŠŠè¿™ä¸ªæ ·æœ¬åŠ å…¥é‡‡æ ·é›†ï¼›
         - åŠ å…¥æ ·æœ¬åï¼Œæ ¹æ®è¯¥æ ·æœ¬é‡Œæ¯ç§å…³ç³»ç±»å‹çš„æ•°é‡ï¼Œæ›´æ–° current_countsï¼›
           æ›´æ–°æ—¶ä¸è¶…è¿‡ target_counts[t]ï¼Œé¿å…ä¸¥é‡è¶…é‡‡æ ·ã€‚
      4. å½“æ‰€æœ‰å…³ç³»ç±»å‹éƒ½è¾¾åˆ°æˆ–è¶…è¿‡ target_counts æ—¶æå‰åœæ­¢ã€‚

    æ³¨æ„ï¼š
      - ä¸€ä¸ªæ ·æœ¬å¯èƒ½å«æœ‰å¤šæ¡ã€å¤šç§å…³ç³»ï¼Œå› æ­¤æœ€ç»ˆæ¯”ä¾‹ä¼šæœ‰è½»å¾®åå·®ï¼Œè¿™æ˜¯å¤šæ ‡ç­¾æ•°æ®å¸¸è§æƒ…å†µã€‚
      - å¦‚æœæƒ³æŠŠ â€œæ²¡æœ‰ä»»ä½• relation çš„æ ·æœ¬â€ ä¹Ÿå½“æˆä¸€ä¸ªæ ·æœ¬çº§åˆ«çš„ none ç±»åˆ«æ§åˆ¶æ¯”ä¾‹ï¼Œ
        å¯ä»¥å‚è€ƒä»£ç ä¸­çš„æ³¨é‡Šä½ç½®åŠ é€»è¾‘ã€‚
    """
    random.seed(seed)

    # 1. ç»Ÿè®¡æ•´ä½“å…³ç³»ç±»åˆ«åˆ†å¸ƒ
    total_counts = count_relation_types(data)
    print("æ€»å…³ç³»ç±»åˆ«è®¡æ•°ï¼š", total_counts)

    if not total_counts:
        print("è­¦å‘Šï¼šæ•°æ®ä¸­æ²¡æœ‰ä»»ä½•å…³ç³»ï¼ˆrelation ä¸ºç©ºï¼‰ï¼Œæ— æ³•æŒ‰å…³ç³»ç±»åˆ«åˆ†å±‚é‡‡æ ·ã€‚")
        return []

    # 2. ç›®æ ‡è®¡æ•°ï¼Œè‡³å°‘ä¸º 1
    target_counts = {
        t: max(1, int(cnt * sample_ratio))
        for t, cnt in total_counts.items()
    }
    print("ç›®æ ‡é‡‡æ ·å…³ç³»ç±»åˆ«è®¡æ•°ï¼š", target_counts)

    current_counts = Counter()
    indices = list(range(len(data)))
    random.shuffle(indices)

    selected_indices = []

    for idx in indices:
        ex = data[idx]
        image_name = ex.get("image_id")
        image_path = f"datasets/MNRE-V2/mnre_image/img_org/test/{image_name}"
        img = cv2.imread(image_path)
        if img is None:
            print(f"æ‰¾ä¸åˆ°å›¾ç‰‡: {image_path}")
            continue

        relations = ex.get("relation", [])

        # ğŸ‘‰ å¦‚æœä½ å¸Œæœ›â€œå®Œå…¨æ²¡æœ‰å…³ç³»çš„æ ·æœ¬â€å½“ä½œä¸€ä¸ªæ ·æœ¬çº§ none ç±»åˆ«æ¥æ§åˆ¶æ¯”ä¾‹ï¼Œ
        # å¯ä»¥æŠŠä¸‹é¢ä¸€æ®µæ³¨é‡Šæ‰“å¼€ï¼Œå¹¶åœ¨ total_counts é‡Œäº‹å…ˆæŠŠ "none" åŠ è¿›å»ã€‚
        #
        # if not relations:
        #     none_type = "none"
        #     if none_type in target_counts and current_counts[none_type] < target_counts[none_type]:
        #         selected_indices.append(idx)
        #         current_counts[none_type] += 1
        #     continue

        if not relations:
            # é»˜è®¤ï¼šrelation ä¸ºç©ºçš„æ ·æœ¬ä¸å‚ä¸åŸºäºå…³ç³»åˆ†å¸ƒçš„é‡‡æ ·
            continue

        # è¯¥æ ·æœ¬ä¸­å…³ç³»ç±»åˆ«åŠå…¶æ•°é‡
        ex_type_counts = Counter(
            rel["type"] for rel in relations if "type" in rel
        )
        if not ex_type_counts:
            continue

        ex_types = set(ex_type_counts.keys())

        # åˆ¤æ–­åŠ å…¥è¯¥æ ·æœ¬æ˜¯å¦æœ‰åŠ©äºâ€œè¡¥è¶³â€æŸäº›å…³ç³»ç±»åˆ«
        if not any(current_counts[t] < target_counts.get(t, 0) for t in ex_types):
            continue

        # åŠ å…¥æ ·æœ¬
        selected_indices.append(idx)

        # æ›´æ–°å½“å‰è®¡æ•°ï¼ˆæŒ‰å…³ç³»æ¡æ•°æ›´æ–°ï¼‰ï¼Œæœ€å¤šç´¯ç§¯åˆ° target_counts[t]
        for t, c in ex_type_counts.items():
            if t not in target_counts:
                continue
            if current_counts[t] < target_counts[t]:
                current_counts[t] = min(current_counts[t] + c, target_counts[t])

        # å¦‚æœæ‰€æœ‰å…³ç³»ç±»åˆ«éƒ½å·²ç»è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œå¯ä»¥æå‰åœæ­¢
        if all(current_counts[t] >= target_counts[t] for t in target_counts):
            break

    sampled_data = [data[i] for i in sorted(selected_indices)]

    print("å®é™…é‡‡æ ·åå…³ç³»ç±»åˆ«è®¡æ•°ï¼š", count_relation_types(sampled_data))
    print("é‡‡æ ·æ ·æœ¬æ•°é‡ï¼š", len(sampled_data))

    return sampled_data


def build_output_path(
    input_path: str,
    base_out_dir: str = "data_process/processed_data"
) -> str:
    """
    æ ¹æ®è¾“å…¥è·¯å¾„è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºè·¯å¾„ï¼š
    ä¾‹å¦‚ï¼š
      input:  UMIE/.../text2spotasoc/relation/mnre/train.json
      output: data_process/processed_data/relation/mnre/train.jsonl
    """
    norm_path = os.path.normpath(input_path)
    parts = norm_path.split(os.sep)

    # æœŸæœ›æœ«å°¾ç»“æ„ä¸º: .../<category>/<dataset>/<split>.json
    if len(parts) < 3:
        raise ValueError(f"è¾“å…¥è·¯å¾„å±‚çº§å¤ªæµ…ï¼Œæ— æ³•è§£æç±»åˆ«å’Œæ•°æ®é›†: {input_path}")

    category = parts[-3]   # relation
    dataset = parts[-2]    # mnre
    split = os.path.splitext(parts[-1])[0]  # train / dev / test

    out_dir = os.path.join(base_out_dir, category, dataset)
    os.makedirs(out_dir, exist_ok=True)

    out_path = os.path.join(out_dir, split + ".jsonl")
    return out_path


if __name__ == "__main__":
    # 1. è¯»å– MNRE æ•°æ®ï¼ˆjsonl / ä¸€è¡Œä¸€ä¸ªæ ·æœ¬ï¼‰
    data_path = "UMIE/text_processing/converted_data/text2spotasoc/relation/MNRE-V2/test.json"
    data = load_jsonl(data_path)
    
    # 2. ç»Ÿè®¡æ•´ä½“å…³ç³»ç±»åˆ«æ•°é‡
    all_rel_counts = count_relation_types(data)
    print("æ•°æ®é›†ä¸­å…³ç³»ç±»åˆ«åˆ†å¸ƒï¼š")
    for t, c in all_rel_counts.items():
        print(f"  {t}: {c}")

    # 3. åšåˆ†å±‚é‡‡æ ·ï¼ˆä¾‹å¦‚é‡‡ 70.1%ï¼‰
    sampled = stratified_sample_keep_relation_ratio(
        data,
        sample_ratio=0.250,
        seed=2025
    )

    # 4. æŠŠé‡‡æ ·ç»“æœå†™åˆ°æ–‡ä»¶
    out_path = build_output_path(data_path)
    with open(out_path, "w", encoding="utf-8") as f:
        for ex in sampled:
            f.write(json.dumps(ex, ensure_ascii=False) + "\n")

    print(f"é‡‡æ ·æ•°æ®å·²ä¿å­˜åˆ°: {out_path}")